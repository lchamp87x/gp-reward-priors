{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1a9880-60c9-4d49-9315-ab54a6d8f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa6ee9c-fe91-4f50-a5fd-06b58dad4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import h5py\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39958da-ea5b-4594-aa8d-d06ad9701de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2931535-25ba-48cb-a50e-2aba587a4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optbnn.bnn.likelihoods import LikGaussian\n",
    "from optbnn.bnn.nets.mlp import MLP\n",
    "from optbnn.bnn.priors import FixedGaussianPrior, OptimGaussianPrior\n",
    "from optbnn.bnn.reparam_nets import GaussianMLPReparameterization\n",
    "from optbnn.gp import kernels, mean_functions\n",
    "from optbnn.gp.models.model import LCFModel\n",
    "from optbnn.gp.reward_functions import pen_task_reward_prior\n",
    "from optbnn.metrics.sampling import compute_rhat_regression\n",
    "from optbnn.prior_mappers.wasserstein_gp_mapper import MapperWassersteinGP\n",
    "from optbnn.sgmcmc_bayes_net.pref_net import PrefNet\n",
    "from optbnn.utils import util\n",
    "from optbnn.utils.normalization import (\n",
    "    normalize_data,\n",
    "    zscore_normalization,\n",
    "    zscore_unnormalization,\n",
    ")\n",
    "from optbnn.utils.rand_generators import DataSetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5472a93-9ac4-486f-a6fe-54d02a307193",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be3dea-9796-4432-8d8e-741c14439c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e777dac-c2aa-419a-90fc-be2311b3dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = \"./exp/reward_learning_gp/pen\"\n",
    "FIG_DIR = os.path.join(OUT_DIR, \"figures\")\n",
    "util.ensure_dir(OUT_DIR)\n",
    "util.ensure_dir(FIG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b955f-81c0-4c95-aed4-d6356982c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(\n",
    "    X, samples, var=None, n_keep=12, color=\"xkcd:bluish\", smooth_q=False, ax=None\n",
    "):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if samples.ndim > 2:\n",
    "        samples = samples.squeeze()\n",
    "    n_keep = int(samples.shape[1] / 10) if n_keep is None else n_keep\n",
    "    keep_idx = np.random.permutation(samples.shape[1])[:n_keep]\n",
    "    mu = samples.mean(1)\n",
    "    if var is None:\n",
    "        q = 97.72  ## corresponds to 2 stdevs in Gaussian\n",
    "        # q = 99.99  ## corresponds to 3 std\n",
    "        Q = np.percentile(samples, [100 - q, q], axis=1)\n",
    "        # ub, lb = Q[1,:], Q[0,:]\n",
    "        ub, lb = mu + 2 * samples.std(1), mu - 2 * samples.std(1)\n",
    "        if smooth_q:\n",
    "            lb = moving_average(lb)\n",
    "            ub = moving_average(ub)\n",
    "    else:\n",
    "        ub = mu + 3 * np.sqrt(var)\n",
    "        lb = mu - 3 * np.sqrt(var)\n",
    "    ####\n",
    "    ax.fill_between(X.flatten(), ub, lb, color=color, alpha=0.25, lw=0)\n",
    "    ax.plot(X, samples[:, keep_idx], color=color, alpha=0.8)\n",
    "    ax.plot(X, mu, color=\"xkcd:red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35abe570-03f2-4999-a77d-c82a1a0b8f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.set_seed(1)\n",
    "\n",
    "# p_mean = np.array([0.0, -1.0, 1.0, 10.0, 50.0, -5.0])\n",
    "p_covariance = np.identity(6)\n",
    "pen_prior = LCFModel(p_covariance, pen_task_reward_prior)\n",
    "pen_prior = pen_prior.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd7d71b-239d-49ef-aad9-0530ecddfc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.set_seed(1)\n",
    "# Initialize BNN Priors\n",
    "width = 64  # Number of units in each hidden layer\n",
    "depth = 3  # Number of hidden layers\n",
    "transfer_fn = \"relu\"  # Activation function\n",
    "\n",
    "# Prior to be optimized\n",
    "opt_bnn = GaussianMLPReparameterization(\n",
    "    input_dim=69, output_dim=1, activation_fn=transfer_fn, hidden_dims=[width] * depth\n",
    ")\n",
    "\n",
    "opt_bnn = opt_bnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c5372-a0cd-4a63-9a79-7092580d6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.set_seed(1)\n",
    "with h5py.File(\"data/adroit_pen/adroit_pen_tuning_set.hdf5\") as f:\n",
    "    data_generator = DataSetSampler(f[\"obs\"][:], f[\"aux_obs\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408baa84-0056-42dc-b5d4-8c79de9ff1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_num_iters = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988373f-92e2-4fbe-bf09-aaccbf3ce01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiialize the Wasserstein optimizer\n",
    "util.set_seed(1)\n",
    "mapper = MapperWassersteinGP(\n",
    "    pen_prior,\n",
    "    opt_bnn,\n",
    "    data_generator,\n",
    "    out_dir=OUT_DIR,\n",
    "    input_dim=69,\n",
    "    n_data=512,\n",
    "    n_gpu=1,\n",
    "    gpu_gp=True,\n",
    ")\n",
    "\n",
    "# Start optimizing the prior\n",
    "w_hist = mapper.optimize(\n",
    "    num_iters=mapper_num_iters,\n",
    "    batches=10,\n",
    "    lr=0.08,\n",
    "    save_ckpt_every=50,\n",
    "    print_every=20,\n",
    ")\n",
    "path = os.path.join(OUT_DIR, \"wsr_values.log\")\n",
    "np.savetxt(path, w_hist, fmt=\"%.6e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae2594-290a-4cb7-8fc9-0888e22041bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize progression of the prior optimization\n",
    "wdist_file = os.path.join(OUT_DIR, \"wsr_values.log\")\n",
    "wdist_vals = np.loadtxt(wdist_file)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3.5))\n",
    "indices = np.arange(mapper_num_iters)[::5]\n",
    "plt.plot(indices, wdist_vals[indices], \"-ko\", ms=4)\n",
    "plt.ylabel(r\"$W_1(p_{gp}, p_{nn})$\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380e5b4-efd6-4537-bc44-db6aa8b7a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the optimize prior\n",
    "util.set_seed(1)\n",
    "ckpt_path = os.path.join(OUT_DIR, \"ckpts\", \"it-{}.ckpt\".format(mapper_num_iters))\n",
    "opt_bnn.load_state_dict(torch.load(ckpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877db13c-4150-4d5b-aff4-4446227f497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw functions from the priors\n",
    "n_plot = 4000\n",
    "util.set_seed(8)\n",
    "X, aux_X = data_generator.get(100)\n",
    "\n",
    "gp_samples = (\n",
    "    pen_prior.sample_functions(X, n_plot, aux_X).detach().cpu().numpy().squeeze()\n",
    ")\n",
    "\n",
    "nngp_samples = opt_bnn.sample_nngp(X, n_plot).detach().cpu().numpy().squeeze()\n",
    "\n",
    "opt_bnn_samples = (\n",
    "    opt_bnn.sample_functions(X.float(), n_plot).detach().cpu().numpy().squeeze()\n",
    ")\n",
    "\n",
    "seq = np.arange(100)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 3))\n",
    "plot_samples(seq, gp_samples, ax=axs[0], n_keep=5)\n",
    "axs[0].set_title(\"GP Prior\")\n",
    "axs[0].set_ylim([-4, 4])\n",
    "\n",
    "plot_samples(seq, nngp_samples, ax=axs[1], color=\"xkcd:grass\", n_keep=5)\n",
    "axs[1].set_title(\"NNGP Prior\")\n",
    "axs[1].set_ylim([-4, 4])\n",
    "\n",
    "plot_samples(seq, opt_bnn_samples, ax=axs[2], color=\"xkcd:yellowish orange\", n_keep=5)\n",
    "axs[2].set_title(\"BNN Prior (NNGP-induced)\")\n",
    "axs[2].set_ylim([-4, 4])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e81d3d9-6a26-4e92-b8ec-6b10290665c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGHMC Hyper-parameters\n",
    "sampling_configs = {\n",
    "    \"batch_size\": 256,  # Mini-batch size\n",
    "    \"num_samples\": 40,  # Total number of samples for each chain\n",
    "    \"n_discarded\": 10,  # Number of the first samples to be discared for each chain\n",
    "    \"num_burn_in_steps\": 2000,  # Number of burn-in steps\n",
    "    \"keep_every\": 2000,  # Thinning interval\n",
    "    \"lr\": 0.01,  # Step size\n",
    "    \"num_chains\": 4,  # Number of chains\n",
    "    \"mdecay\": 0.01,  # Momentum coefficient\n",
    "    \"print_every_n_samples\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b3f77-8744-4497-83fc-2da32564cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, _ = util.load_pref_data(\n",
    "    \"data/adroit_pen/AdroitHandPen-v1_pref_b.hdf5\", 0.8\n",
    ")\n",
    "X_test = X_test[:, :, :, :69].reshape(-1, 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c647e8-a915-4583-baa6-76d6773404ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the prior\n",
    "util.set_seed(1)\n",
    "prior = FixedGaussianPrior(std=1.0)\n",
    "\n",
    "# Setup likelihood\n",
    "net = MLP(69, 1, [width] * depth, transfer_fn)\n",
    "likelihood = LikCE()\n",
    "\n",
    "# Initialize the sampler\n",
    "saved_dir = os.path.join(OUT_DIR, \"sampling_std\")\n",
    "util.ensure_dir(saved_dir)\n",
    "bayes_net_std = PrefNet(net, likelihood, prior, saved_dir, n_gpu=0)\n",
    "\n",
    "# Start sampling\n",
    "bayes_net_std.sample_multi_chains(X_train, y_train, **sampling_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de93c7-d85a-462c-a103-bfeb32078f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "util.set_seed(1)\n",
    "_, _, bnn_std_preds = bayes_net_std.predict(X_test, True)\n",
    "# Convergence diagnostics using the R-hat statistic\n",
    "r_hat = compute_rhat_regression(bnn_std_preds, sampling_configs[\"num_chains\"])\n",
    "print(r\"R-hat: mean {:.4f} std {:.4f}\".format(float(r_hat.mean()), float(r_hat.std())))\n",
    "bnn_std_preds = bnn_std_preds.squeeze().T\n",
    "\n",
    "# Save the predictions\n",
    "posterior_std_path = os.path.join(OUT_DIR, \"posterior_std.npz\")\n",
    "np.savez(posterior_std_path, bnn_samples=bnn_std_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713f681-0a3f-4ad1-987a-e3a53ecda4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the optimized prior\n",
    "ckpt_path = os.path.join(OUT_DIR, \"ckpts\", \"it-{}.ckpt\".format(mapper_num_iters))\n",
    "prior = OptimGaussianPrior(ckpt_path)\n",
    "\n",
    "# Setup likelihood\n",
    "net = MLP(69, 1, [width] * depth, transfer_fn)\n",
    "likelihood = LikCE()\n",
    "\n",
    "# Initialize the sampler\n",
    "saved_dir = os.path.join(OUT_DIR, \"sampling_optim\")\n",
    "util.ensure_dir(saved_dir)\n",
    "bayes_net_optim = PrefNet(net, likelihood, prior, saved_dir, n_gpu=0)\n",
    "\n",
    "# Start sampling\n",
    "bayes_net_optim.sample_multi_chains(X_train, y_train, **sampling_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5415c38-55aa-4b75-a688-62beec590097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "util.set_seed(1)\n",
    "_, _, bnn_optim_preds = bayes_net_optim.predict(X_test, True)\n",
    "\n",
    "# Convergence diagnostics using the R-hat statistic\n",
    "r_hat = compute_rhat_regression(bnn_optim_preds, sampling_configs[\"num_chains\"])\n",
    "print(r\"R-hat: mean {:.4f} std {:.4f}\".format(float(r_hat.mean()), float(r_hat.std())))\n",
    "bnn_optim_preds = bnn_optim_preds.squeeze().T\n",
    "\n",
    "# Save the predictions\n",
    "posterior_optim_path = os.path.join(OUT_DIR, \"posterior_optim.npz\")\n",
    "np.savez(posterior_optim_path, bnn_samples=bnn_optim_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd33e251-3345-4bf0-82b0-c359f25f5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.set_seed(8)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 3))\n",
    "plot_samples(seq, bnn_std_preds[100:200], ax=axs[0], color=\"xkcd:grass\", n_keep=16)\n",
    "axs[0].set_title(\"BNN Posterior (Fixed)\")\n",
    "axs[0].set_ylim([-4, 4])\n",
    "\n",
    "plot_samples(\n",
    "    seq, bnn_optim_preds[100:200], ax=axs[1], color=\"xkcd:yellowish orange\", n_keep=16\n",
    ")\n",
    "axs[1].set_title(\"BNN Posterior (GP-induced)\")\n",
    "axs[1].set_ylim([-4, 4])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
