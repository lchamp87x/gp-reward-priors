{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1B2mCGHnBLr"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnl9Vf40nCXY"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9ppXZYlT6lg"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIuI6BVrnEm_"
   },
   "outputs": [],
   "source": [
    "from optbnn.bnn.likelihoods import LikGaussian\n",
    "from optbnn.bnn.nets.mlp import MLP\n",
    "from optbnn.bnn.priors import FixedGaussianPrior, OptimGaussianPrior\n",
    "from optbnn.bnn.reparam_nets import GaussianMLPReparameterization\n",
    "from optbnn.gp import kernels, mean_functions\n",
    "from optbnn.gp.models.gpr import GPR\n",
    "from optbnn.metrics.sampling import compute_rhat_regression\n",
    "from optbnn.prior_mappers.wasserstein_mapper import (\n",
    "    MapperWasserstein,\n",
    "    WassersteinDistance,\n",
    ")\n",
    "from optbnn.sgmcmc_bayes_net.regression_net import RegressionNet\n",
    "from optbnn.utils import util\n",
    "from optbnn.utils.normalization import (\n",
    "    normalize_data,\n",
    "    zscore_normalization,\n",
    "    zscore_unnormalization,\n",
    ")\n",
    "from optbnn.utils.rand_generators import GridGenerator, MeasureSetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2kqa0ZvOnpFT"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NT0a1-vtn5rR"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxvYimbvnrlW"
   },
   "outputs": [],
   "source": [
    "OUT_DIR = \"./exp/1D_synthetic/tanh_gaussian_new\"\n",
    "FIG_DIR = os.path.join(OUT_DIR, \"figures\")\n",
    "util.ensure_dir(OUT_DIR)\n",
    "util.ensure_dir(FIG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y38dIUCHUMnz"
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFGmnnDAnwH_"
   },
   "outputs": [],
   "source": [
    "def make_random_gap(X, gap_ratio=0.2):\n",
    "    a, b = X.min(), X.max()\n",
    "    gap_a = a + np.random.rand() * (b - a) * (1 - gap_ratio)\n",
    "    gap_b = gap_a + (b - a) * gap_ratio\n",
    "    idx = np.logical_and(gap_a < X, X < gap_b)\n",
    "    if gap_a - a > b - gap_b:\n",
    "        X[idx] = a + np.random.rand(idx.sum()) * (gap_a - a)\n",
    "    else:\n",
    "        X[idx] = gap_b + np.random.rand(idx.sum()) * (b - gap_b)\n",
    "\n",
    "\n",
    "def gp_sample(X, ampl=1, leng=1, sn2=0.1):\n",
    "    n, x = X.shape[0], X / leng\n",
    "    sum_xx = np.sum(x * x, 1).reshape(-1, 1).repeat(n, 1)\n",
    "    D = sum_xx + sum_xx.transpose() - 2 * np.matmul(x, x.transpose())\n",
    "    C = ampl**2 * np.exp(-0.5 * D) + np.eye(n) * sn2\n",
    "    return np.random.multivariate_normal(np.zeros(n), C).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def plot_samples(\n",
    "    X, samples, var=None, n_keep=12, color=\"xkcd:bluish\", smooth_q=False, ax=None\n",
    "):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if samples.ndim > 2:\n",
    "        samples = samples.squeeze()\n",
    "    n_keep = int(samples.shape[1] / 10) if n_keep is None else n_keep\n",
    "    keep_idx = np.random.permutation(samples.shape[1])[:n_keep]\n",
    "    mu = samples.mean(1)\n",
    "    if var is None:\n",
    "        q = 97.72  ## corresponds to 2 stdevs in Gaussian\n",
    "        # q = 99.99  ## corresponds to 3 std\n",
    "        Q = np.percentile(samples, [100 - q, q], axis=1)\n",
    "        # ub, lb = Q[1,:], Q[0,:]\n",
    "        ub, lb = mu + 2 * samples.std(1), mu - 2 * samples.std(1)\n",
    "        if smooth_q:\n",
    "            lb = moving_average(lb)\n",
    "            ub = moving_average(ub)\n",
    "    else:\n",
    "        ub = mu + 3 * np.sqrt(var)\n",
    "        lb = mu - 3 * np.sqrt(var)\n",
    "    ####\n",
    "    ax.fill_between(X.flatten(), ub, lb, color=color, alpha=0.25, lw=0)\n",
    "    ax.plot(X, samples[:, keep_idx], color=color, alpha=0.8)\n",
    "    ax.plot(X, mu, color=\"xkcd:red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iug6JinmURT1"
   },
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26NbSsWunyxA"
   },
   "outputs": [],
   "source": [
    "util.set_seed(1)\n",
    "\n",
    "N = 64\n",
    "M = 100\n",
    "a, b = -10, 10\n",
    "\n",
    "# Generate data\n",
    "X = np.random.rand(N, 1) * (b - a) + a\n",
    "make_random_gap(X, gap_ratio=0.4)\n",
    "y = gp_sample(X, ampl=1.6, leng=1.8)\n",
    "Xtest = np.linspace(a - 5, b + 5, M).reshape(-1, 1)\n",
    "\n",
    "# Normalize the dataset\n",
    "X_, X_mean, X_std = zscore_normalization(X)\n",
    "y_, y_mean, y_std = zscore_normalization(y)\n",
    "Xtest_, _, _ = zscore_normalization(Xtest, X_mean, X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "03_8HJeMnz4f",
    "outputId": "9f910f97-c845-44f1-8282-790e81efaf4b"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(X, y, \"ko\", ms=5)\n",
    "plt.title(\"Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53FskE1vn1fm"
   },
   "outputs": [],
   "source": [
    "Xtest_tensor = torch.from_numpy(Xtest_).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWUR3HHCUbQE"
   },
   "source": [
    "# Initialize Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msOBawHzn25R"
   },
   "outputs": [],
   "source": [
    "util.set_seed(1)\n",
    "\n",
    "# GP hyper-parameters\n",
    "sn2 = 0.1  # noise variance\n",
    "leng = 0.6  # lengthscale\n",
    "ampl = 1.0  # amplitude\n",
    "\n",
    "# Initialize GP Prior\n",
    "kernel = kernels.RBF(\n",
    "    input_dim=1,\n",
    "    ARD=True,\n",
    "    lengthscales=torch.tensor([leng], dtype=torch.double),\n",
    "    variance=torch.tensor([ampl], dtype=torch.double),\n",
    ")\n",
    "\n",
    "gpmodel = GPR(\n",
    "    X=torch.from_numpy(X_).to(device),\n",
    "    Y=torch.from_numpy(y_).reshape([-1, 1]).to(device),\n",
    "    kern=kernel,\n",
    "    mean_function=mean_functions.Zero(),\n",
    ")\n",
    "gpmodel.likelihood.variance.set(sn2)\n",
    "gpmodel = gpmodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUqx_kspn80s"
   },
   "outputs": [],
   "source": [
    "util.set_seed(1)\n",
    "# Initialize BNN Priors\n",
    "width = 50  # Number of units in each hidden layer\n",
    "depth = 3  # Number of hidden layers\n",
    "transfer_fn = \"tanh\"  # Activation function\n",
    "\n",
    "# Initialize Gaussian prior.\n",
    "# Fixed Prior\n",
    "std_bnn = GaussianMLPReparameterization(\n",
    "    input_dim=1, output_dim=1, activation_fn=transfer_fn, hidden_dims=[width] * depth\n",
    ")\n",
    "\n",
    "# Prior to be optimized\n",
    "opt_bnn = GaussianMLPReparameterization(\n",
    "    input_dim=1, output_dim=1, activation_fn=transfer_fn, hidden_dims=[width] * depth\n",
    ")\n",
    "\n",
    "std_bnn = std_bnn.to(device)\n",
    "opt_bnn = opt_bnn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMvnn6QcU74G"
   },
   "source": [
    "# Optimize Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvaV8IRon_T_"
   },
   "outputs": [],
   "source": [
    "# We use a grid of 200 data points in [-6, 6] for the measurement set\n",
    "util.set_seed(1)\n",
    "data_generator = GridGenerator(-6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aApH-z6FoU63"
   },
   "outputs": [],
   "source": [
    "mapper_num_iters = 800  # Define the number of iterations of Wasserstein optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "omsaBUdeoXAg",
    "outputId": "a03ddffb-d54b-471a-f47c-11928bf0de7c"
   },
   "outputs": [],
   "source": [
    "# Initiialize the Wasserstein optimizer\n",
    "util.set_seed(1)\n",
    "mapper = MapperWasserstein(\n",
    "    gpmodel,\n",
    "    opt_bnn,\n",
    "    data_generator,\n",
    "    out_dir=OUT_DIR,\n",
    "    wasserstein_steps=(0, 1000),\n",
    "    wasserstein_lr=0.08,\n",
    "    n_data=200,\n",
    "    n_gpu=1,\n",
    "    gpu_gp=True,\n",
    ")\n",
    "\n",
    "# Start optimizing the prior\n",
    "w_hist = mapper.optimize(\n",
    "    num_iters=mapper_num_iters,\n",
    "    n_samples=512,\n",
    "    lr=0.01,\n",
    "    save_ckpt_every=50,\n",
    "    print_every=20,\n",
    "    debug=True,\n",
    ")\n",
    "path = os.path.join(OUT_DIR, \"wsr_values.log\")\n",
    "np.savetxt(path, w_hist, fmt=\"%.6e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "RDWXRInxoYJZ",
    "outputId": "2572a81b-0d7a-4fcb-cd0c-156dc41935c6"
   },
   "outputs": [],
   "source": [
    "# Visualize progression of the prior optimization\n",
    "wdist_file = os.path.join(OUT_DIR, \"wsr_values.log\")\n",
    "wdist_vals = np.loadtxt(wdist_file)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3.5))\n",
    "indices = np.arange(mapper_num_iters)[::5]\n",
    "plt.plot(indices, wdist_vals[indices], \"-ko\", ms=4)\n",
    "plt.ylabel(r\"$W_1(p_{gp}, p_{nn})$\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkWysKY2VPj5"
   },
   "source": [
    "# Visualize Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJRPMJoGV1vo",
    "outputId": "2bc190ed-a5eb-4bc7-99dc-c72860d7b4e8"
   },
   "outputs": [],
   "source": [
    "# Load the optimize prior\n",
    "util.set_seed(1)\n",
    "ckpt_path = os.path.join(OUT_DIR, \"ckpts\", \"it-{}.ckpt\".format(mapper_num_iters))\n",
    "opt_bnn.load_state_dict(torch.load(ckpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "4SDMHE4rV3k7",
    "outputId": "d1dcc719-bb4c-4f1c-e72c-d1374c180997"
   },
   "outputs": [],
   "source": [
    "# Draw functions from the priors\n",
    "n_plot = 4000\n",
    "util.set_seed(8)\n",
    "\n",
    "gp_samples = (\n",
    "    gpmodel.sample_functions(Xtest_tensor, n_plot).detach().cpu().numpy().squeeze()\n",
    ")\n",
    "gp_samples = zscore_unnormalization(gp_samples, y_mean, y_std)\n",
    "\n",
    "std_bnn_samples = (\n",
    "    std_bnn.sample_functions(Xtest_tensor.float(), n_plot)\n",
    "    .detach()\n",
    "    .cpu()\n",
    "    .numpy()\n",
    "    .squeeze()\n",
    ")\n",
    "std_bnn_samples = zscore_unnormalization(std_bnn_samples, y_mean, y_std)\n",
    "\n",
    "opt_bnn_samples = (\n",
    "    opt_bnn.sample_functions(Xtest_tensor.float(), n_plot)\n",
    "    .detach()\n",
    "    .cpu()\n",
    "    .numpy()\n",
    "    .squeeze()\n",
    ")\n",
    "opt_bnn_samples = zscore_unnormalization(opt_bnn_samples, y_mean, y_std)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 3))\n",
    "plot_samples(Xtest, gp_samples, ax=axs[0], n_keep=5)\n",
    "axs[0].set_title(\"GP Prior\")\n",
    "axs[0].set_ylim([-5, 5])\n",
    "\n",
    "plot_samples(Xtest, std_bnn_samples, ax=axs[1], color=\"xkcd:grass\", n_keep=5)\n",
    "axs[1].set_title(\"BNN Prior (Fixed)\")\n",
    "axs[1].set_ylim([-5, 5])\n",
    "\n",
    "plot_samples(Xtest, opt_bnn_samples, ax=axs[2], color=\"xkcd:yellowish orange\", n_keep=5)\n",
    "axs[2].set_title(\"BNN Prior (GP-induced)\")\n",
    "axs[2].set_ylim([-5, 5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAIXoQSzWsn5"
   },
   "source": [
    "# Posterior Inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OXXZsQVW6zb"
   },
   "source": [
    "## GP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMgd8zcpW84-"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "util.set_seed(1)\n",
    "gp_preds = gpmodel.predict_f_samples(Xtest_tensor, 1000)\n",
    "gp_preds = gp_preds.detach().cpu().numpy().squeeze()\n",
    "gp_preds = zscore_unnormalization(gp_preds, y_mean, y_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74F8uHcjYAPW"
   },
   "source": [
    "## BNN with Fixed Prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUL1TvMUW5qI"
   },
   "outputs": [],
   "source": [
    "# SGHMC Hyper-parameters\n",
    "sampling_configs = {\n",
    "    \"batch_size\": 32,  # Mini-batch size\n",
    "    \"num_samples\": 30,  # Total number of samples for each chain\n",
    "    \"n_discarded\": 10,  # Number of the first samples to be discared for each chain\n",
    "    \"num_burn_in_steps\": 2000,  # Number of burn-in steps\n",
    "    \"keep_every\": 200,  # Thinning interval\n",
    "    \"lr\": 0.01,  # Step size\n",
    "    \"num_chains\": 4,  # Number of chains\n",
    "    \"mdecay\": 0.01,  # Momentum coefficient\n",
    "    \"print_every_n_samples\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1X5PtyfWZWK4",
    "outputId": "08e7f675-c090-412e-f527-948d92af467e"
   },
   "outputs": [],
   "source": [
    "# Initialize the prior\n",
    "util.set_seed(1)\n",
    "prior = FixedGaussianPrior(std=1.0)\n",
    "\n",
    "# Setup likelihood\n",
    "net = MLP(1, 1, [width] * depth, transfer_fn)\n",
    "likelihood = LikGaussian(sn2)\n",
    "\n",
    "# Initialize the sampler\n",
    "saved_dir = os.path.join(OUT_DIR, \"sampling_std\")\n",
    "util.ensure_dir(saved_dir)\n",
    "bayes_net_std = RegressionNet(net, likelihood, prior, saved_dir, n_gpu=0)\n",
    "\n",
    "# Start sampling\n",
    "bayes_net_std.sample_multi_chains(X, y, **sampling_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k3lTwi4PajhD",
    "outputId": "9ef91e5e-859e-4cf8-9436-388d6f8bad58"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "util.set_seed(1)\n",
    "_, _, bnn_std_preds = bayes_net_std.predict(Xtest, True)\n",
    "\n",
    "# Convergence diagnostics using the R-hat statistic\n",
    "r_hat = compute_rhat_regression(bnn_std_preds, sampling_configs[\"num_chains\"])\n",
    "print(r\"R-hat: mean {:.4f} std {:.4f}\".format(float(r_hat.mean()), float(r_hat.std())))\n",
    "bnn_std_preds = bnn_std_preds.squeeze().T\n",
    "\n",
    "# Save the predictions\n",
    "posterior_std_path = os.path.join(OUT_DIR, \"posterior_std.npz\")\n",
    "np.savez(posterior_std_path, bnn_samples=bnn_std_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bi59yHyrarcv"
   },
   "source": [
    "## BNN with Optimized Prior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vAxFWoi5asZz",
    "outputId": "a5ff6c87-ec21-49b1-f88d-26b04742e3e0"
   },
   "outputs": [],
   "source": [
    "# Load the optimized prior\n",
    "ckpt_path = os.path.join(OUT_DIR, \"ckpts\", \"it-{}.ckpt\".format(mapper_num_iters))\n",
    "prior = OptimGaussianPrior(ckpt_path)\n",
    "\n",
    "# Setup likelihood\n",
    "net = MLP(1, 1, [width] * depth, transfer_fn)\n",
    "likelihood = LikGaussian(sn2)\n",
    "\n",
    "# Initialize the sampler\n",
    "saved_dir = os.path.join(OUT_DIR, \"sampling_optim\")\n",
    "util.ensure_dir(saved_dir)\n",
    "bayes_net_optim = RegressionNet(net, likelihood, prior, saved_dir, n_gpu=0)\n",
    "\n",
    "# Start sampling\n",
    "bayes_net_optim.sample_multi_chains(X, y, **sampling_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mD75gPiHbF6i",
    "outputId": "23eaeea8-f5b0-4c22-ca24-a1f8b74209f9"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "util.set_seed(1)\n",
    "_, _, bnn_optim_preds = bayes_net_optim.predict(Xtest, True)\n",
    "\n",
    "# Convergence diagnostics using the R-hat statistic\n",
    "r_hat = compute_rhat_regression(bnn_optim_preds, sampling_configs[\"num_chains\"])\n",
    "print(r\"R-hat: mean {:.4f} std {:.4f}\".format(float(r_hat.mean()), float(r_hat.std())))\n",
    "bnn_optim_preds = bnn_optim_preds.squeeze().T\n",
    "\n",
    "# Save the predictions\n",
    "posterior_optim_path = os.path.join(OUT_DIR, \"posterior_optim.npz\")\n",
    "np.savez(posterior_optim_path, bnn_samples=bnn_optim_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqZpIJWngSGj"
   },
   "source": [
    "## Visualize Predictive Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "dloTbr21gUl9",
    "outputId": "efbf2c17-414c-4c5f-a22d-c1ddc7f63857"
   },
   "outputs": [],
   "source": [
    "util.set_seed(8)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 3))\n",
    "\n",
    "plot_samples(Xtest, gp_preds, ax=axs[0], n_keep=16)\n",
    "axs[0].plot(X, y, \"ok\", zorder=10, ms=5)\n",
    "axs[0].set_title(\"GP Posterior\")\n",
    "axs[0].set_ylim([-4, 4])\n",
    "\n",
    "plot_samples(Xtest, bnn_std_preds, ax=axs[1], color=\"xkcd:grass\", n_keep=16)\n",
    "axs[1].plot(X, y, \"ok\", zorder=10, ms=5)\n",
    "axs[1].set_title(\"BNN Posterior (Fixed)\")\n",
    "axs[1].set_ylim([-4, 4])\n",
    "\n",
    "plot_samples(\n",
    "    Xtest, bnn_optim_preds, ax=axs[2], color=\"xkcd:yellowish orange\", n_keep=16\n",
    ")\n",
    "axs[2].plot(X, y, \"ok\", zorder=10, ms=5)\n",
    "axs[2].set_title(\"BNN Posterior (GP-induced)\")\n",
    "axs[2].set_ylim([-4, 4])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1D_regression_gaussian_prior.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
